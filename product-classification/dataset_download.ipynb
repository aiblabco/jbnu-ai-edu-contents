{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import _pickle as cPickle\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Loader(object):\n",
    "    \"\"\"\n",
    "    interface for data loader wrappers\n",
    "    \"\"\"\n",
    "    def load_data(self, file_name):\n",
    "        \"\"\"\n",
    "        loads the data into memory\n",
    "        :param file_name: name of the file to load\n",
    "        :return: pandas object\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "class JSONLoader(Loader):\n",
    "    def __init__(self, read_mode='rb'):\n",
    "        self.read_mode = read_mode\n",
    "\n",
    "    def load_data(self, file_name):\n",
    "        \"\"\"\n",
    "        :param file_name: complete path to open\n",
    "        :return: pandas dataframe\n",
    "        \"\"\"\n",
    "        try:\n",
    "            i = 0\n",
    "            df = {}\n",
    "            for d in self._parse(file_name):\n",
    "                df[i] = d\n",
    "                i += 1\n",
    "            return pd.DataFrame.from_dict(df, orient='index')\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def _parse(self, file_name):\n",
    "        g = gzip.open(file_name, self.read_mode)\n",
    "        for l in g:\n",
    "            yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cat(l):\n",
    "    return l[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file_path corresponds to the file of the .gz file which contains the JSON file. \n",
    "product_path = '/mnt/share/datasets/product-classification/meta_Electronics.json.gz'\n",
    "#product_path = 'D:\\\\TUM\\\\courses\\\\sem_3\\\\practical DM\\\\datasets\\\\meta_Electronics.json.gz'\n",
    "loader = JSONLoader()\n",
    "product = loader.load_data(product_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product.categories = product.categories.apply(flatten)\n",
    "product.categories = product.categories.apply(get_cat)\n",
    "\n",
    "# code that did the magic of running in sub-seconds complexity.\n",
    "#sin_cat_dict = Series(product.categories.values,index=product.asin).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "product.categories.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change the threshold to experiment\n",
    "threshold = 7000\n",
    "percent = []\n",
    "cats = []\n",
    "counter = 0\n",
    "counts = product.categories.value_counts()\n",
    "for key, val in counts.iteritems():\n",
    "    if val >= threshold:\n",
    "        counter+=1\n",
    "        percent.append( (val/product.shape[0]) * 100)\n",
    "        cats.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_cat_subset = product[product.categories.isin(cats)]\n",
    "product_cat_subset.categories.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of categories\n",
    "len(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent of data we are using\n",
    "sum(percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change the project path to root of the repository. make sure that datasets folder is added to .gitignore\n",
    "project_path = '.'\n",
    "datasets_path = os.path.join(project_path, 'datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(datasets_path):\n",
    "    os.makedirs(datasets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import random\n",
    "import time\n",
    "for cat in cats:\n",
    "    \n",
    "    # switch off the download_cutoff_activate if you want to download all images in the category.\n",
    "    download_cutoff_activate = True\n",
    "    \n",
    "    # change the download cutoff if required, minimum it should be 7k\n",
    "    download_cutoff = 10000\n",
    "    product_cat_subset_subset = product_cat_subset[product_cat_subset.categories == cat]\n",
    "    cat_path = os.path.join(datasets_path, cat)\n",
    "    if not os.path.exists(cat_path):\n",
    "        os.makedirs(cat_path)\n",
    "    os.chdir(cat_path)\n",
    "    imurls = product_cat_subset_subset.imUrl.tolist()\n",
    "    imurls = list(set(imurls))\n",
    "    if download_cutoff_activate and len(imurls) > download_cutoff:\n",
    "        # randomly sample 10k urls from categories that contain more than 10k images to reduce download time\n",
    "        imurls = random.sample(imurls, download_cutoff)\n",
    "        \n",
    "        # sanity check that sampling worked correctly\n",
    "        assert len(imurls) == download_cutoff\n",
    "        \n",
    "    print('number of urls to be downloaded for category: ' + cat + ' is: ' + str(len(imurls)))\n",
    "    for idx, url in enumerate(imurls):\n",
    "        try:\n",
    "            # logging\n",
    "            if idx % 1000 == 0:\n",
    "                print('images downloaded: ' + str(idx))\n",
    "            \n",
    "            # download the image using wget in cat_path\n",
    "            file = wget.download(url)\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
